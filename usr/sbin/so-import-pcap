#!/bin/bash

# Copyright 2014,2015,2016,2017,2018 Security Onion Solutions, LLC

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

COMMON="/usr/sbin/so-common"
if ! [ -f $COMMON ]; then
	echo "$COMMON not found."
	echo "This script requires Security Onion Elastic Stack Release Candidate 2 (14.04.5.8 ISO) or later."
	exit
fi
source $COMMON

CONF="/etc/nsm/securityonion.conf"
if ! [ -f $CONF ]; then
	echo "$CONF not found."
	echo "Please run Setup."
	exit
fi
source $CONF

SENSORTAB="/etc/nsm/sensortab"
if ! [ -f $SENSORTAB ]; then
	echo "$SENSORTAB not found."
	echo "This machine must be configured for network sensor services."
	exit
fi
SENSOR=`grep -v "^#" $SENSORTAB  |head -1 |awk '{print $1}'`

SENSORCONF="/etc/nsm/$SENSOR/sensor.conf"
if ! [ -f $SENSORCONF ]; then
	echo "$SENSORCONF not found."
	echo "This machine must be configured for network sensor services to continue."
	exit
fi
source $SENSORCONF

SGUILDCONF="/etc/sguild/sguild.conf"
if ! [ -f $SGUILDCONF ]; then
	echo "$SGUILDCONF not found."
	echo "This machine must be running sguild to continue."
	exit
fi

SYSLOGCONF="/etc/syslog-ng/syslog-ng.conf"
if ! [ -f $SYSLOGCONF ]; then
	echo "$SYSLOGCONF not found."
	echo "This machine must be running syslog-ng to continue."
	exit
fi

LOGSTASH_SNORT=/etc/logstash/conf.d/1033_preprocess_snort.conf
if ! [ -f $LOGSTASH_SNORT ]; then
	echo "$LOGSTASH_SNORT not found."
	echo "Exiting."
	exit
fi

# Check to see if this is a sensor before continuing
if [ -f /root/.ssh/securityonion_ssh.conf ]; then
	echo "This machine appears to be a sensor connected to a distributed deployment."
	echo "This script was designed for standalone systems designated for so-import-pcap."
	exit
fi

# Output the program name
cat << EOF

so-import-pcap

EOF

function usage {
cat << EOF
This is a quick and dirty EXPERIMENTAL script that will import one or more pcaps into Security Onion.

It will do the following:
- stop and disable Curator to avoid closing old indices
- generate IDS alerts using Snort or Suricata
- generate Bro logs
- store alerts and logs with original timestamps
- split traffic into separate daily pcaps and store them where sguil's pcap_agent can find them

Requirements:
- You must be running at least Security Onion Elastic Stack Release Candidate 2 (14.04.5.8 ISO).
- You must have a sniffing interface defined (you can choose Evaluation Mode in the Setup wizard).

Warnings:
- Do NOT run this on a production deployment. It is designed for standalone systems designated for so-import-pcap.

Usage:
Please supply at least one pcap file.

For example, to import a single pcap named import.pcap:
so-import-pcap import.pcap

To import multiple pcaps:
so-import-pcap import1.pcap import2.pcap

EOF
}

# If no parameters supplied, display usage
if [ $# -eq 0 ]; then
	usage
	exit
fi

# Verify that all parameters are files
for i in $@; do
	if ! [ -f $i ]; then
		usage
		echo "$i is not a valid file!"
		exit
	fi
done

# Create temp pcap and set permissions
echo "Please wait while..."
echo "...creating temp pcap for processing."
PCAP=`mktemp /tmp/so-import-pcap-XXXXXXXXXX.pcap`
if ! mergecap -w $PCAP $@; then
	echo "Error while merging!"
	exit
fi
chmod 444 $PCAP

# Check to see if file is a valid PCAP
capinfos $PCAP 2>&1 | grep "The file appears to be damaged or corrupt." && exit

# make sure sguild is running with DEBUG 2
if ! grep "set DEBUG 2" $SGUILDCONF >/dev/null 2>&1; then
	echo "...setting sguild debug to 2 and restarting sguild."
	sed -i 's|set DEBUG.*$|set DEBUG 2|g' $SGUILDCONF
	/usr/sbin/nsm_server_ps-restart >/dev/null 2>&1
fi

# make sure syslog-ng is configured to pick up sguild logs
if ! grep "/var/log/nsm/securityonion/sguild.log" $SYSLOGCONF >/dev/null 2>&1; then
	echo "...configuring syslog-ng to pick up sguild logs."
cat << EOF >> $SYSLOGCONF

# added by so-import-pcap
source s_sguil { file("/var/log/nsm/securityonion/sguild.log" program_override("snort")); };
filter f_sguil { message("Alert Received"); };
log {
        source(s_sguil);
        filter(f_sguil);
        destination(d_logstash);
};
EOF
	service syslog-ng restart >/dev/null 2>&1
fi

# make sure Logstash is configured to parse sguild logs
if ! grep "DATA:timestamp" $LOGSTASH_SNORT > /dev/null 2>&1; then
	echo -n "...configuring logstash to parse sguild logs (this may take a few minutes, but should only need to be done once)..."
	sed -i 's|"message", "%{GREEDYDATA:alert}"]|"message", "\\A%{TIME} pid\\(%{INT}\\)  Alert Received: %{INT} %{INT:priority} %{DATA:classification} %{DATA:interface} \\{%{DATA:timestamp}} %{INT} %{INT} \\{%{DATA:alert}\} %{IP:source_ip} %{IP:destination_ip} %{INT:protocol} %{INT:source_port} %{INT:destination_port} %{INT:gid} %{INT:sid} %{INT:rev} %{INT} %{INT}\\Z",\n                "message", "%{GREEDYDATA:alert}"]\n    }\n\n    if [timestamp] {\n        mutate {\n                add_field => { "logstash_timestamp" => "%{@timestamp}" }\n        }\n        mutate {\n                convert => { "logstash_timestamp" => "string" }\n        }\n        date {\n                match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]\n        }\n        mutate {\n                rename => { "logstash_timestamp" => "timestamp" }\n        }|g' $LOGSTASH_SNORT
	docker restart so-logstash >/dev/null 2>&1
	if (timeout 10m tail -F -n0 "/var/log/logstash/logstash.log" &) | grep -q "Pipelines running" ; then
	    echo "done."
	else
	    echo "failed."
	    exit
	fi
fi

# Stop curator if running
if docker ps |grep curator >/dev/null 2>&1; then
	echo "...stopping curator."
	docker stop so-curator >/dev/null 2>&1
fi

# Disable curator
if [ "$CURATOR_ENABLED" = "yes" ]; then
	echo "...disabling curator."
	sed -i 's|CURATOR_ENABLED="yes"|CURATOR_ENABLED="no"|g' /etc/nsm/securityonion.conf
fi

# In RC2, CapMe defaults to only allowing to search back 5 years.
# Let's increase that to 50 years just in case.
# This fix has already been applied by default in RC3.
if grep " - 5 " /var/www/so/capme/.inc/callback-elastic.php >/dev/null 2>&1; then
	echo "...adjusting CapMe to allow pcaps up to 50 years old."
	sed -i 's| - 5 | - 50 |g' /var/www/so/capme/.inc/callback-elastic.php
fi

# Generate IDS alerts and write them to standard pipeline for consumption via Sguil agents
if [ "$IDS_ENGINE_ENABLED" = "yes" ]; then
	if [ "$ENGINE" = "snort" ]; then
		echo "...analyzing traffic with Snort."
		snort --daq pcap -c /etc/nsm/$SENSOR/snort.conf -u sguil -g sguil -l /nsm/sensor_data/$SENSOR/snort-1 -r $PCAP >/dev/null 2>&1
	else
		echo "...analyzing traffic with Suricata."
		suricata --user sguil --group sguil -c /etc/nsm/$SENSOR/suricata.yaml -l /nsm/sensor_data/$SENSOR --runmode single -r $PCAP >/dev/null 2>&1
	fi
fi

# Generate Bro logs and write them to /nsm/import/bro/
if [ "$BRO_ENABLED" = "yes" ] ; then
	BRODIR="/nsm/import/bro"
	echo "...analyzing traffic with Bro."
	mkdir -p $BRODIR
	cd $BRODIR
	/opt/bro/bin/bro -r $PCAP local >/dev/null 2>&1
	cd - >/dev/null
fi

# Split traffic into daily directories so that sguil's pcap_agent can find it
if [ "$PCAP_AGENT_ENABLED" = "yes" ] ; then
	START=`capinfos $PCAP -a |grep "Start time:" | awk '{print $4,$5,$7}'`
	START=`date +%Y-%m-%d --date="$START"`
	END=`capinfos $PCAP -e |grep "End time:" | awk '{print $4,$5,$7}'`
	END=`date +%Y-%m-%d --date="$END"`
	ENDNEXT=`date +%Y-%m-%d --date="$END 1 day"`
	CURRENT="$START"
	while [ "$CURRENT" != "$ENDNEXT" ]; do
		EPOCH=`date +%s --date="$CURRENT"`
		PCAPDIR="/nsm/sensor_data/$SENSOR/dailylogs/$CURRENT"
		FILE="$PCAPDIR/snort.log.$EPOCH"
		mkdir -p $PCAPDIR
		CURRENTNEXT=`date +%Y-%m-%d --date="$CURRENT 1 day"`
		echo "...writing $FILE"
		editcap -F libpcap -A "$CURRENT 00:00:00" -B "$CURRENTNEXT 00:00:00" $PCAP $FILE
		CURRENT=`date +%Y-%m-%d --date="$CURRENT 1 day"`
	done
fi

# Remove temp file
rm -f $PCAP

# Output final message
cat << EOF

Import complete!

You can use this hyperlink to view data in the time range of your import:
https://localhost/app/kibana#/dashboard/94b52620-342a-11e7-9d52-4f090484f59e?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:'${START}T00:00:00.000Z',mode:absolute,to:'${ENDNEXT}T00:00:00.000Z'))

or you can manually set your Time Range to be:
From: $START    To: $ENDNEXT
EOF
